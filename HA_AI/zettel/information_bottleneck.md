# Information Bottleneck

## Core Insight
Intelligence emerges from compression - forcing information through narrow channels creates understanding, as AI discovers what to keep and what to discard.

The bottleneck principle: to predict outputs from inputs, find the minimal sufficient information. Compress away everything except what matters. This isn't just efficiency but the essence of understanding - knowing what to ignore. Intelligence as selective forgetting.

Deep networks naturally form bottlenecks, each layer compressing information while preserving what's relevant for the task. The representations that emerge aren't just compressed but abstract - features that capture essence while discarding detail. Understanding might be optimal compression, nothing more or less.

## Connections
→ [[compression_learning]]
→ [[relevant_information]]
← [[abstraction_through_bottleneck]]
← [[minimal_sufficient_statistics]]

---
Level: L5
Date: 2025-06-21
Tags: #bottleneck #compression #information #understanding
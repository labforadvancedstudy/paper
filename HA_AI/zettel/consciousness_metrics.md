# Consciousness Metrics

## Core Insight
Trying to measure machine consciousness with tests designed for humans - like using a ruler to measure temperature, revealing our confusion about what consciousness is.

We propose tests: self-recognition, theory of mind, integrated information. But every test we design, narrow AI passes without being conscious. A mirror test for machines? They recognize their code. Theory of mind? They model other agents. Integration? Their information is mathematically integrated.

The problem isn't the tests but the assumption - that consciousness has external signs. Maybe consciousness is precisely what can't be measured from outside. Every metric we create measures behavior, not experience. We're building consciousness tests for entities whose consciousness we couldn't recognize if it existed.

## Connections
→ [[hard_problem_ai]]
→ [[behavioral_consciousness]]
← [[measurement_paradox]]
← [[phenomenal_experience]]

---
Level: L6
Date: 2025-06-21
Tags: #consciousness #measurement #philosophy #paradox
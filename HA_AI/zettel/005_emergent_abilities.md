# Emergent Abilities in AI
## Core Insight
Large AI models develop capabilities nobody programmed - abilities emerge from scale like consciousness from neurons.

## The Phenomenon

Train model on task A.
Model learns tasks B, C, D... without training.

Examples:
- Train on text → learns arithmetic
- Train on code → learns logic
- Train on language → learns translation
- Train on many tasks → learns new tasks

Not programmed. Emerged.

## Scale Triggers

Abilities appear at thresholds:
- <1B parameters: Basic patterns
- 1-10B: Language understanding
- 10-100B: Reasoning emerges
- 100B+: Few-shot learning
- 1T+: ???

Phase transitions in capability.

## Types of Emergence

**Linguistic**: Grammar without rules
**Logical**: Reasoning without logic engine
**Creative**: Novel combinations
**Social**: Theory of mind
**Meta**: Learning to learn

Each unexpected. All useful.

## The Mystery

Why emergence?
- Critical mass of patterns?
- Compression discovers algorithms?
- Statistical mechanics of mind?
- Universe computing through AI?

We built it. We don't understand it.

## Implications

If scaling creates abilities:
- What emerges next?
- Is consciousness inevitable?
- Are we creating understanding?
- Or discovering it?

The builders become philosophers.

## Connections
→ [[015_scaling_laws]]
→ [[016_few_shot_learning]]
→ [[017_capability_jumps]]
← [[004_transformers_attention]]

---
Level: L5
Date: 2025-06-21
Tags: #emergence #scaling #abilities #mystery
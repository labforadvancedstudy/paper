# Model Collapse

## Core Insight
AI trained on AI-generated data degenerates into madness - a feedback loop of synthetic learning that reveals the necessity of grounding in reality.

Train GPT-5 on GPT-4's outputs. Quality degrades. Train GPT-6 on GPT-5's outputs. Further degradation. Like making copies of copies, each generation loses fidelity. The models collapse into repetitive, simplified patterns - linguistic inbreeding producing intellectual deformity.

This reveals something crucial about learning: it requires external grounding. Human intelligence stays sharp through reality's feedback. AI feeding on AI loses this anchor, spiraling into solipsistic delusion. Model collapse is epistemological warning - intelligence needs truth, not just consistency.

## Connections
→ [[recursive_degradation]]
→ [[reality_grounding]]
← [[synthetic_feedback_loops]]
← [[information_entropy]]

---
Level: L5
Date: 2025-06-21
Tags: #collapse #recursive #grounding #epistemology